# Ray's Portfolio - Robots.txt
# Allow all search engines to crawl the entire site

User-agent: *
Allow: /

# Block access to potentially sensitive directories
Disallow: /.git/
Disallow: /node_modules/
Disallow: /.vscode/
Disallow: /temp/
Disallow: /draft/

# Allow specific important files
Allow: /assets/
Allow: /css/
Allow: /js/
Allow: /data/

# Crawl delay (optional - prevents aggressive crawling)
Crawl-delay: 1

# Sitemap location (when available)
# Sitemap: https://ll-0013py.github.io/portfolio/sitemap.xml